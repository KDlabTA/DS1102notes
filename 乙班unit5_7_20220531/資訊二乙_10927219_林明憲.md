# 資料結構與演算法 筆記 單元5~7 10927219
資訊二乙 10927219 林明憲

## 單元 5 雜湊 Hashing

### (1) 雜湊原理 Hashing Basics
* An array that contains the table items, as assigned by a **hash function**.
* Key -> Location Mapping
* Perfect Hash Function
    * Maps each search key into a ==**unique location**==.
    * Possible only if ==**all**== the search keys are known.

---

### (2) 雜湊碰撞 Hashing Collision
* <font color="#F99A00">**Definition**</font>
    Occurs when the hash function maps **more than one items** all having **different search keys** into ==**the same array location**==.
    
---

### (3) 雜湊需求 Hashing Requirements
* <font color="#F00">**Hash Functions**</font>
    * *Assign each search key to a single location*.
    1. **Easy** and **fast** to compute.
    2. Places items **evenly** throughout the hash table.
    3. Involves the **entire** search key.
    4. Uses a **prime** base, if it uses **modulo arithmetic**.

* <font color="#F00">**Collision Resolution Schemes**</font>
    * Assigns **distinct locations** in the hash table to items involved in a collision.

---

### (4) 雜湊函式 Hashing Functions
* <font color="#3d6df8">**Simple Hash Functions**</font>
    1. Digit Selection
        * Does **not** distribute items **evenly**.
    2. Folding
        * Involves the **entire** search key.
    3. Modulo Arithmetic
        * The table size should be **prime**.
    4. Converting Character Strings
        * Use **integers** in the hash function instead of search strings.
        * **Positional Sum**

---

### (5) 雜湊碰撞解決 Hashing Collision Resolution
* <font color="#6414fa">**Open addressing**</font>
    * ==**Probe**== for an **empty location** in the hash table.
    * As the hash table **fills**, ==**collisions increase**==.
    * Increase of table ==**size**== ( Need to hash **again**).
    1. **++Linear Probing++**
        * Search the **first location** and then the next etc.
        * Primary **clustering** problem.
        * Empty locations after **deletions** would **incorrectly stop** a probing sequence.
        * Create **key independent** probing sequences.
    2. **++Quadratic Probing++**
        * Search the first location and then continue at the increments of 1^2^, 2^2^, 3^2^, and so on.
        * **Probing sequence** may not visit **every location** in the hash table.
        * Secondary **clustering** problem.
        * Table size must be **prime**
        * Create **key independent** probing sequences.
    3. **++Double Hashing++**
        * Uses **two hash functions** h~1~, h~2~ to reduce clustering problems.
        * h~1~ for the first location and h~2 (**h1!=h2**, **h2(key)>0**) for the **step size**
        * If **table size** and **step size** are **relatively prime**, the probing sequence will visit *every** location in the hash table.
        * Creates **key dependent** probing sequences.
* <font color="#6414fa">**Restructuring the hash table**</font>
    * Allows the hash table to **accommodate** ==**more than one**== item in the same location.
    1. **++Buckets++**
        * Each location in the hash table is itself an **array**.
    2. **++Separate Chaining++**
        * Each hash table location keeps a **linked list**.

---

### (6) 雜湊效率 Hashing Efficiency
* <font color="#027557">**Average-case Analysis**</font>
    * Load factor **α**
        * α = Current number of items in the table / table size
        * Measure how full a hash table is.
    * Depends on whether the search is successful.
        * **Unsuccessful searches** generally require more time than **successful searches**.
    * Inefficient Operations on Hashing
        * **Traversal**
        * **NN Search**
        * **Range Query**

![](https://i.imgur.com/7y9m1TF.png)

---

### (7) Data With Multiple Organizations
* Many applications require a data organization that **simultaneously** supports several different data-management tasks.
    * Several independent data structures
        * Do **not support** all operations efficiently.
        * Waste **space**.
    * Interdependent data structures
        * Provide a better way to support a **multiple** organization of data.

---

## 單元 6 圖形概論 Graph Basics

### (1) 圖形基礎術語 Basic Terminologies
* Undirected Graph
* Directed Graph (digraph)
* Adjacent Vertices
* Edge
* Path
* Cycle
* Simple Path
* Simple Cycle
* Connected Connected Graph
* Complete Graph
* Strong Connected Graph
* Weighted Graph

---

### (2) 圖形表示法 Graph Representations
* <font color="#F99A00">**Common Operations**</font>
    1. Determine whether there is an edge from vertex i to vertex j.
    2. Find all vertices adjacent to a given vertex i.
* <font color="#F99A00">**Adjacency Matrix**</font>
    * Supports operation **1** more efficiently.
* <font color="#F99A00">**Adjacency List**</font>
    * Supports operation **2** more efficiently.
    * Often requires **less space** than an adjacency matrix.
* <font color="#F99A00">**Sequential representation**</font>
    * **nodes** + **edges**
---

### (3) 圖形遍歷 Graph Traversals
* Visits all the **vertices** that it can reach.
* Visits all **vertices** of the graph if and only if **connected**.
* To prevent **indefinite loops**.
* <font color="#F00">**Graph Traversals**</font>
    * **Depth-First Search** Traversal (DFS)
        * Proceeds along a path from a vertex v as **deeply** into the graph as possible before backing up.
        * **Last visited, first explored.**
        * **simple recursive form**
        * **stack**
    * **Breadth-First Search** Traversal (BFS)
        * Visit every vertex **adjacent** to a vertex v before visiting any other vertex.
        * **First visited, first explored.**
        * **not simple recursive form**
        * **queue**

![](https://i.imgur.com/8znbhVX.png)

---

## 單元 7 圖形應用 Graph Application

### (1) Topological Sort Definition
* <font color="#3d6df8">**Topological order**</font>
    * A list of vertices in a **digraph without cycles** such that vertex x **precedes** vertex y if there is a directed edge from x to y.
    * Several topological orders are possible for a given graph.
* <font color="#3d6df8">**Topological sorting**</font>
    * Arranging the vertices into a **topological order**.

---

### (2) Topological Sort Algorithms
* <font color="#6414fa">**Algorithm 1**</font>
    1. Find a vertex that has **no successor**.
    2. Add the vertex to the **beginning** of a list.
    3. **Remove** that vertex from the graph, and all **edges** that lead to it.
    4. Repeat the previous steps until the graph is **empty**.
    5. When the loop ends, the list of vertices will be in topological order.
* <font color="#6414fa">**Algorithm 2**</font>
    1. A modification of the **iterative DFS** algorithm.
    2. Push all vertices that have **no predecessor** onto a **stack**.
    3. Each time you **pop** a vertex from the stack, add it to the **beginning** of a list of vertices.
    4. When the traversal ends, the list of vertices will be in topological order.

---

### (3) Spanning Tree Definition
* A tree is an **undirected** connected graph **without cycles**.
* A **spanning tree** of a connected undirected graph is a **subgraph** that contains all of **vertices** and enough of its **edges** to form a tree.

---

### (4) Counting Spanning Trees
* n^n-2^ Various Vertex Labeling
* <font color="#027557">**Prüfer Sequence**</font>
    * Heinz Prüfer (1918)
    1. Leaf with the **smallest** label.
    2. Keep the label of its parent.
* <font color="#027557">**Rationale**</font>
    * For n labels, there are **n^n-2^** sequences of length n-2.
    * Each **Prüfer sequence** can be converted to a unique labeled tree with n vertices (a spanning tree).
    * For a complete complete graph with n vertices, there are **n^n-2^** spanning trees.

---

### (5) DFS and BFS for Spanning Trees
* <font color="#F99A00">**Create a Spanning Tree**</font>
    * Traverse the graph using either **DFS** or **BFS** and **mark the edges** that you follow.
    * After the traversal is completed, the graph’s **vertices** and **marked edges** form a spanning tree.

---

### (6) Minimum Spanning Tree Definition
* <font color="#F00">**Cost of Spanning Tree**</font>
    * **Sum** of the **edge weights** on a spanning tree.
* <font color="#F00">**Minimum Spanning Tree**</font>
    * A minimum spanning tree of a connected undirected graph has a **minimal edge-weight sum**.

---

### (7) Minimum Spanning Trees Algorithms
* <font color="#fa87ec">**Prim’s Algorithm**</font>
    * Robert Prim (1957)
    1. Find the **least-cost** edge (v, u) from a visited vertex v to some unvisited vertex u.
    2. **Mark** u as **visited**.
    3. Add the vertex u and the edge (v, u) to the minimum spanning tree.
    4. Repeat the above steps until **all vertices are visited**.
* <font color="#fa87ec">**Kruskal’s Algorithm**</font>
    * Joseph Kruskal (1956)
    1. Create a forest, where each vertex is a tree.
    2. Find the **least-cost** edge (v, u) where vertex v and vertex u are from two **different trees**.
    3. **Merge** the trees of vertex v and vertex u, and add the edge (v, u) to the minimum spanning tree.
    4. Repeat the above steps until **|V|-1** edges.
* <font color="#fa87ec">**Sollin’s Algorithm**</font>
    * Otakar Borůvka (1926)
    * Sollin (1965)
    1. Create a forest, where each vertex is a tree.
    2. For each tree T, do the following steps.
        1. Find the **least-cost** edge (v, u) where vertex v is **in** T and vertex u is **outside** T.
        2. **Merge** the trees of vertex v and vertex u, and add the edge (v, u) to the minimum spanning tree.
    3. Repeat step 2 until only **one tree is left**.

---

### (8) Shortest Paths
* <font color="#32d1d1">**Dijkstra’s Algorithm**</font>
    * Edsger Wybe Dijkstra (1930-2002)
    * Find the **shortest paths** between a given **origin** and **all other vertices**.
    1. Initialize **vertexSet** and **weight**; v = v~0~;
    2. Update weight for each vertex u not in vertexSet, which is adjacent to v.
    3. Find the **shortest path** from o to u among every path that **starts** from o, **passes** vertices **in vertexSet**, and **ends** at a vertex **not in vertexSet**.
    4. Repeat steps 2, 3 until **no more vertex** can be added.
* <font color="#32d1d1">**Dijkstra’s Algorithm**</font>
    * Robert Floyd (1962
    * S. Warshall (1962)
    1. Initialize **distance matrix D-1** = **adjacency matrix**.
    2. **k=0 to |V|-1**

---

## 資料與圖片來源

* CYCU i-learning 資料結構 吳宜鴻教授